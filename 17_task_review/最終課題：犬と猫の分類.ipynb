{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee810256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 2 classes.\n",
      "Found 100 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# データの読み込み\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory\n",
    "# 画像サイズが元々75x75なので、2倍くらい近いの160x160にリサイズした。\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../dog_cat_photos/train\",\n",
    "    image_size=(160, 160),\n",
    "    label_mode=\"binary\",\n",
    "#     batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../dog_cat_photos/test\",\n",
    "    image_size=(160, 160),\n",
    "    label_mode=\"binary\",\n",
    "#     batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af8def86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の水増しをする関数の定義（コピペ）\n",
    "def flip_left_right(image, label):   # 左右反転\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image, label\n",
    "\n",
    "def flip_up_down(image, label):      # 上下反転\n",
    "    image = tf.image.flip_up_down(image)\n",
    "    return image, label\n",
    "\n",
    "def rot90(image, label):             # 反時計回りに90度回転\n",
    "    image = tf.image.rot90(image)\n",
    "    return image, label\n",
    "\n",
    "def rot180(image, label):            # 反時計回りに180度回転\n",
    "    image = tf.image.rot90(image, k=2)\n",
    "    return image, label\n",
    "\n",
    "def rot270(image, label):            # 反時計回りに270度回転\n",
    "    image = tf.image.rot90(image, k=3)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95caf225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "class_names # ['cat', 'dog']\n",
    "\n",
    "# データの水増しの処理\n",
    "train_dataset_lr     = train_dataset.map(flip_left_right)\n",
    "train_dataset_ud     = train_dataset.map(flip_up_down)\n",
    "train_dataset_rot90  = train_dataset.map(rot90)\n",
    "train_dataset_rot180 = train_dataset.map(rot180)\n",
    "train_dataset_rot270 = train_dataset.map(rot270)\n",
    "\n",
    "# 水増しデータの結合\n",
    "train_dataset = train_dataset.concatenate(train_dataset_lr)\n",
    "train_dataset = train_dataset.concatenate(train_dataset_ud)\n",
    "train_dataset = train_dataset.concatenate(train_dataset_rot90)\n",
    "train_dataset = train_dataset.concatenate(train_dataset_rot180)\n",
    "train_dataset = train_dataset.concatenate(train_dataset_rot270)\n",
    "\n",
    "# またシャフルします\n",
    "train_dataset = train_dataset.shuffle(32)\n",
    "\n",
    "# 画像の表示チェック（回転後の画像もでます）\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# plt.figure(figsize=(10, 10))\n",
    "# \n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels[i].numpy().astype(\"uint8\")[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.7147 - loss: 0.5282\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9220 - loss: 0.1804\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9612 - loss: 0.1176\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9779 - loss: 0.0862\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9759 - loss: 0.0824\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9819 - loss: 0.0684\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9880 - loss: 0.0577\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9962 - loss: 0.0486\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9891 - loss: 0.0492\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9955 - loss: 0.0363\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9981 - loss: 0.0315\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9964 - loss: 0.0323\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9947 - loss: 0.0303\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9968 - loss: 0.0258\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9987 - loss: 0.0250\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9996 - loss: 0.0223\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9998 - loss: 0.0185\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9997 - loss: 0.0181\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9999 - loss: 0.0201\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0145\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.56452860e-04],\n",
       "       [9.94075090e-05],\n",
       "       [8.42718524e-04],\n",
       "       [6.68382621e-04],\n",
       "       [1.18076845e-04],\n",
       "       [3.70117807e-04],\n",
       "       [1.58082439e-05],\n",
       "       [4.61969496e-04],\n",
       "       [5.36618290e-06],\n",
       "       [2.14216736e-04],\n",
       "       [3.33827265e-05],\n",
       "       [5.91541082e-03],\n",
       "       [5.41372174e-05],\n",
       "       [7.27386141e-05],\n",
       "       [3.79653866e-05],\n",
       "       [5.01459144e-05],\n",
       "       [2.73665559e-04],\n",
       "       [1.82001331e-05],\n",
       "       [7.07216968e-05],\n",
       "       [1.95712084e-03],\n",
       "       [6.74995135e-06],\n",
       "       [4.31366591e-03],\n",
       "       [3.78720870e-05],\n",
       "       [1.26945204e-04],\n",
       "       [4.36035275e-01],\n",
       "       [1.57812145e-04],\n",
       "       [3.11875367e-03],\n",
       "       [3.42462845e-05],\n",
       "       [9.74697003e-04],\n",
       "       [6.08316695e-05],\n",
       "       [1.54428827e-02],\n",
       "       [8.57832849e-01],\n",
       "       [3.26351392e-06],\n",
       "       [1.36084752e-02],\n",
       "       [3.51802795e-04],\n",
       "       [9.86474276e-01],\n",
       "       [1.04535501e-02],\n",
       "       [2.62735819e-04],\n",
       "       [5.08262496e-03],\n",
       "       [4.08142398e-04],\n",
       "       [2.94068101e-04],\n",
       "       [1.09951397e-05],\n",
       "       [1.10203116e-04],\n",
       "       [4.39957648e-06],\n",
       "       [1.37327224e-01],\n",
       "       [1.23418635e-02],\n",
       "       [4.16546158e-04],\n",
       "       [9.85157567e-06],\n",
       "       [5.99492788e-01],\n",
       "       [4.68034443e-04],\n",
       "       [9.99698877e-01],\n",
       "       [9.99992728e-01],\n",
       "       [9.99997795e-01],\n",
       "       [9.99949038e-01],\n",
       "       [9.99189615e-01],\n",
       "       [5.46147883e-01],\n",
       "       [9.99949336e-01],\n",
       "       [9.99918222e-01],\n",
       "       [9.98860061e-01],\n",
       "       [9.99477267e-01],\n",
       "       [9.99996185e-01],\n",
       "       [9.98993695e-01],\n",
       "       [9.87957299e-01],\n",
       "       [9.99806106e-01],\n",
       "       [9.99992311e-01],\n",
       "       [9.99254584e-01],\n",
       "       [9.99997139e-01],\n",
       "       [9.99928713e-01],\n",
       "       [9.99974012e-01],\n",
       "       [9.99809980e-01],\n",
       "       [9.97415602e-01],\n",
       "       [9.99684334e-01],\n",
       "       [9.99840856e-01],\n",
       "       [9.98999417e-01],\n",
       "       [9.98340607e-01],\n",
       "       [9.99999642e-01],\n",
       "       [9.99978840e-01],\n",
       "       [9.99932766e-01],\n",
       "       [9.99986708e-01],\n",
       "       [7.37569988e-01],\n",
       "       [9.99796093e-01],\n",
       "       [9.85655606e-01],\n",
       "       [9.99838769e-01],\n",
       "       [9.98602867e-01],\n",
       "       [9.99997079e-01],\n",
       "       [9.99700189e-01],\n",
       "       [9.99994278e-01],\n",
       "       [9.99993443e-01],\n",
       "       [9.99997735e-01],\n",
       "       [9.99987662e-01],\n",
       "       [9.99994755e-01],\n",
       "       [9.99641001e-01],\n",
       "       [9.99965131e-01],\n",
       "       [9.99991298e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99708056e-01],\n",
       "       [9.99916613e-01],\n",
       "       [9.99935746e-01],\n",
       "       [9.99738157e-01],\n",
       "       [9.92048144e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# リサイズ処理はimage_dataset_from_directoryで行われているので、ここではデータの水増しのみを行う\n",
    "\n",
    "# MobileNetV2 のモデルを利用\n",
    "input_layer = tf.keras.Input(shape=(160, 160, 3))   # 入力層\n",
    "l_layer = tf.keras.applications.mobilenet_v2.preprocess_input(input_layer)   # 前処理（正規化）をする層\n",
    "\n",
    "# MobileNetV2の重みファイルのパス\n",
    "# ここでは、事前にダウンロードしておいた重みファイルを指定する。\n",
    "# 指定する原因は、\"imagenet\"でダウンロードするとSSLエラーが出られます。\n",
    "weights_path = './mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n",
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape=(160, 160, 3),\n",
    "    input_tensor=l_layer,\n",
    "    include_top=False,\n",
    "    weights=weights_path,\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Dense層を追加する\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "# base_modelに先ほどのDense層を追加したモデルを作成する\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    output_layer\n",
    "])\n",
    "\n",
    "# modelをcompileする\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# modelに学習させる\n",
    "model.fit(train_dataset, epochs=20)\n",
    "\n",
    "# テストデータで分類を実行する\n",
    "pred_data = model.predict(test_dataset)\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f18d2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9661 - loss: 0.0971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08927605301141739, 0.9700000286102295]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正答率のチェック\n",
    "model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
